<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">


  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="css/scrolling-nav.css" rel="stylesheet">

</head>

<body id="page-top">

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav">
    <div class="container">
      <a class="navbar-brand js-scroll-trigger" href="#page-top"></a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>

        </ul>
      </div>
    </div>
  </nav>

  <header class="bg-primary text-white">
    <div class="container text-center">
      <h1>Workshop on Trustworthy NLP (TrustNLP)</h1>
    </div>
  </header>

  <section id="about">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto">
          <h2></h2>
          <p class="lead">
Recent progress in Artificial Intelligence (AI) and Natural Language
Processing (NLP) has greatly increased their presence in everyday
consumer products in the last decade. Common examples include virtual
assistants, recommendation systems, and personal healthcare management
systems, among others. Advancements in these fields have historically
been driven by the goal of improving model performance as measured by
accuracy, but recently the NLP research community has started
incorporating additional constraints to make sure models are fair and
privacy-preserving. However, these constraints are not often considered
together, which is important since there are critical questions at the
intersection of these constraints such as the tension between
simultaneously meeting privacy objectives and fairness objectives, which
requires knowledge about the demographics a user belongs to.

In this workshop, we aim to bring together these distinct yet closely
related topics. Specifically, we invite papers which focus on developing
models that are “explainable, fair, privacy-preserving, causal, and
robust” (Trustworthy ML Initiative). Topics of interest include (but are not
limited to):
 </p>
          <ul>
            <li>Differential Privacy</li>
            <li> Bias: Evaluation and Treatmentse</li>
            <li>Model Explainability and Interpretabilityr</li>
            <li>Transparency, Accountability, and Ethics</li>
            <li>Industry applications of Trustworthy NLP</li>
            <li>Causal Inference</li>
            <li>Secure and trustworthy data generation</li>
          </ul>
        </div>
      </div>
    </div>
  </section>

  <section id="services" class="bg-light">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto">
               <h2>Organizers</h2>
          <ul>
            <li>Yada Pruksachatkun - Alexa AI</li>
             <li>Anil Ramakrishna - Alexa AI</li>
             <li>Kai-Wei Chang - UCLA, Amazon Visiting Academic</li>
             <li>Satyapriya Krishna, Alexa AI</li>
             <li>Jwala Dhamala, Alexa AI</li>
             <li>Tanaya Guha, University of Warwick</li>
             <li>Xiang Ren, USC</li>

          </ul>
          <h2>Program Committee  </h2>
          <ul>
            <li>Rahul Gupta - Alexa AI</li>
<li>Willie Boag - Massachusetts Institute of Technology</li>
<li>Naveen Kumar - Disney Research</li>
            <li>-Nikita Nangia - New York University</li>
<li> He He - New York University</li>
<li> Jieyu Zhao - University of California Los Angeles</li>
<li> Nanyun Peng - University of California Los Angeles</li>
<li> Spandana Gella - Alexa AI</li>
<li> Moin Nadeem - Massachusetts Institute of Technology</li>
<li> Maarten Sap - University of Washington</li>
<li> Tianlu Wang - University of Virginia</li>
<li> William Wang - University of Santa Barbara</li>
<li> Joe Near - University of Vermont</li>
<li> David Darais - Galois</li>
<li> Pratik Gajane - Department of Computer Science, Montanuniversitat Leoben, Austria</li>
<li> Paul Pu Liang - Carnegie Mellon University</li>
<li> Hila Gonen - Bar-Ilan University</li>
<li> Patricia Thaine - University of Toronto</li>
<li> Jamie Hayes - Google DeepMind, University College London, UK</li>
<li> Emily Sheng - University of California Los Angeles</li>
<li> Isar Nejadgholi -  IMRSV Data Labs</li>
<li> Anthony Rios - University of Texas at San Antonio</li>
          </ul>
        </div>
      </div>
    </div>
  </section>

  <section id="contact">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto">
          <h2>Contact us</h2>
          <p> For questions, please contact us at trustnlporganizers@gmail.com</p>
        </div>
      </div>
    </div>
  </section>

  <!-- Footer -->
  <footer class="py-5 bg-dark">
    <div class="container">
      <p class="m-0 text-center text-white">Copyright &copy; TrustNLP 2020</p>
    </div>
    <!-- /.container -->
  </footer>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Plugin JavaScript -->
  <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

  <!-- Custom JavaScript for this theme -->
  <script src="js/scrolling-nav.js"></script>

</body>

</html>
